{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 6: Reinforcement Learning#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concept of learning by doing with rewards and punishment. The Machine uses it to predict a future state at t+1 with all the data available up till t."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5 different advertisements: which one is the best one? Each has a different distribution of customer spendings. We want to find the best one while we are exploring so as to limit the amount of money not invested in the best one. <br>\n",
    "The regular exploration way would be a big AB-test. This type of problem is known as a **Multi-arm bandit Problem**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Description:\n",
    "+ We have d ads, each time a customer enters the website a random ad is displayed\n",
    "+ If he clicks on it, reward is 1 if not reward is 0\n",
    "+ Goal is to maximize the reward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Upper Confidence Bound ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first way of tackling such a problem is the UCB."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process is:\n",
    "+ Assign confidence band for each machine expected return\n",
    "+ Pick the one with the highest Upper bound: is it a win? a loss?\n",
    "+ Compute the average return and compute the new Upper and Lower bounds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Coding process is:\n",
    "+ **Step 1**: For each ad {i}, compute:\n",
    "    <br>$N_i(n)$ i.e. the number of times the ad was selected up till round n. \n",
    "    <br>$R_i(n)$ i.e. the sum of the rewards for that specific ad up till round n.\n",
    "\n",
    "+ **Step 2**: From these two numbers, compute:\n",
    "    <br>$\\bar{r_i}(n) = \\frac{R_i(n)}{N_i(n)}$ i.e. the average reward for each ad up till round n.\n",
    "    <br>$[\\bar{r_i}(n) - \\Delta_i(n) ; \\bar{r_i}(n) + \\Delta_i(n)]$ i.e. the confidence interval at round n.\n",
    "    <br>with $\\Delta_i(n) = \\sqrt{\\frac{3}{2}*\\frac{log(n)}{N_i(n)}}$\n",
    "    \n",
    "+ **Step 3**: Select the ad that has the highest $\\bar{r_i}(n) + \\Delta_i(n)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementing UCB\n",
    "import math\n",
    "N = 10000\n",
    "d = 10\n",
    "ads_selected = []\n",
    "numbers_of_selections = [0] * d\n",
    "sums_of_rewards = [0] * d\n",
    "total_reward = 0\n",
    "for n in range(0, N):\n",
    "    ad = 0\n",
    "    max_upper_bound = 0\n",
    "    for i in range(0, d):\n",
    "        if (numbers_of_selections[i] > 0):\n",
    "            average_reward = sums_of_rewards[i] / numbers_of_selections[i]\n",
    "            delta_i = math.sqrt(3/2 * math.log(n + 1) / numbers_of_selections[i])\n",
    "            upper_bound = average_reward + delta_i\n",
    "        else:\n",
    "            upper_bound = 1e400\n",
    "        if upper_bound > max_upper_bound:\n",
    "            max_upper_bound = upper_bound\n",
    "            ad = i\n",
    "    ads_selected.append(ad)\n",
    "    numbers_of_selections[ad] = numbers_of_selections[ad] + 1\n",
    "    reward = dataset.values[n, ad]\n",
    "    sums_of_rewards[ad] = sums_of_rewards[ad] + reward\n",
    "    total_reward = total_reward + reward\n",
    "\n",
    "# Visualising the results\n",
    "plt.hist(ads_selected)\n",
    "plt.title('Histogram of ads selections')\n",
    "plt.xlabel('Ads')\n",
    "plt.ylabel('Number of times each ad was selected')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Thomson Sampling ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other way: we try to guess where the expected return of each machine is. We are not trying to guess the distribution behind machines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process is:\n",
    "+ Pick each machine once\n",
    "+ Imagine the possible distribution for each machine\n",
    "+ Do an imaginary pick of each machine, actually pick the one that gives the best imaginary run\n",
    "+ Refine the distribution of that machine\n",
    "+ Repeat, you'll naturally refine more and more the best machine until you get good enough distribution that will let you stay with the perfect machine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| UCB | Thomson Sampling |\n",
    "|:-----: | :-----: |\n",
    "|Deterministic|Probabilistic|\n",
    "|Requires update every round|Can accomodate delayed feedback|\n",
    "||Better Empirical Evidence|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Coding process is:\n",
    "+ **Step 1**: At each round, we need to compute for each ad {i}:\n",
    "    <br>$N_i^1(n)$ i.e. the number of times the ad i had reward 1 up till round n. \n",
    "    <br>$N_i^0(n)$ i.e. the number of times the ad i had reward 0 up till round n.\n",
    "\n",
    "+ **Step 2**: For each ad, we take a random draw from the distribution below:\n",
    "    <br>$\\theta_i(n) = \\beta(N_i^1(n) + 1 ; N_i^0(n) + 1)$\n",
    "    \n",
    "+ **Step 3**: Select the ad that has the highest $\\theta_i(n)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
