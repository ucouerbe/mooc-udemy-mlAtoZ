{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 2: Regression #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regression Template\n",
    "\n",
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Importing the dataset\n",
    "dataset = pd.read_csv('Position_Salaries.csv')\n",
    "X = dataset.iloc[:, 1:2].values\n",
    "y = dataset.iloc[:, 2].values\n",
    "\n",
    "# Splitting the dataset into the Training set and Test set\n",
    "\"\"\"from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\"\"\"\n",
    "\n",
    "# Feature Scaling\n",
    "\"\"\"from sklearn.preprocessing import StandardScaler\n",
    "sc_X = StandardScaler()\n",
    "X_train = sc_X.fit_transform(X_train)\n",
    "X_test = sc_X.transform(X_test)\n",
    "sc_y = StandardScaler()\n",
    "y_train = sc_y.fit_transform(y_train)\"\"\"\n",
    "\n",
    "# Fitting the Regression Model to the dataset\n",
    "# Create your regressor here\n",
    "\n",
    "# Predicting a new result\n",
    "y_pred = regressor.predict(6.5)\n",
    "\n",
    "# Visualising the Regression results\n",
    "plt.scatter(X, y, color = 'red')\n",
    "plt.plot(X, regressor.predict(X), color = 'blue')\n",
    "plt.title('Truth or Bluff (Regression Model)')\n",
    "plt.xlabel('Position level')\n",
    "plt.ylabel('Salary')\n",
    "plt.show()\n",
    "\n",
    "# Visualising the Regression results (for higher resolution and smoother curve)\n",
    "X_grid = np.arange(min(X), max(X), 0.1)\n",
    "X_grid = X_grid.reshape((len(X_grid), 1))\n",
    "plt.scatter(X, y, color = 'red')\n",
    "plt.plot(X_grid, regressor.predict(X_grid), color = 'blue')\n",
    "plt.title('Truth or Bluff (Regression Model)')\n",
    "plt.xlabel('Position level')\n",
    "plt.ylabel('Salary')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Simple linear Regression ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting Simple Linear Regression to the Training set\n",
    "from sklearn.linear_model import LinearRegression\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(X_train, y_train)\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = regressor.predict(X_test)\n",
    "\n",
    "# Visualising the Training set results\n",
    "plt.scatter(X_train, y_train, color = 'red')\n",
    "plt.plot(X_train, regressor.predict(X_train), color = 'blue')\n",
    "plt.title('Salary vs Experience (Training set)')\n",
    "plt.xlabel('Years of Experience')\n",
    "plt.ylabel('Salary')\n",
    "plt.show()\n",
    "\n",
    "# Visualising the Test set results\n",
    "plt.scatter(X_test, y_test, color = 'red')\n",
    "plt.plot(X_train, regressor.predict(X_train), color = 'blue')\n",
    "plt.title('Salary vs Experience (Test set)')\n",
    "plt.xlabel('Years of Experience')\n",
    "plt.ylabel('Salary')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Multiple linear Regressions ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assumptions of Linear Regressions:\n",
    "- Linearity\n",
    "- Homoscedacity\n",
    "- Multivariate normality\n",
    "- Independance of errors\n",
    "- Lack of multicolinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding categorical data\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "labelencoder = LabelEncoder()\n",
    "X[:, 3] = labelencoder.fit_transform(X[:, 3])\n",
    "onehotencoder = OneHotEncoder(categorical_features = [3])\n",
    "X = onehotencoder.fit_transform(X).toarray()\n",
    "\n",
    "# Avoiding the Dummy Variable Trap\n",
    "X = X[:, 1:]\n",
    "\n",
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n",
    "\n",
    "# Fitting Multiple Linear Regression to the Training set\n",
    "from sklearn.linear_model import LinearRegression\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(X_train, y_train)\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a model:\n",
    "- All-in\n",
    "- Backward Elimination\n",
    "- Forward Selection\n",
    "- Bi directional Elimination\n",
    "- Score Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the optimal model using Backward Elimination\n",
    "import statsmodels.formula.api as sm\n",
    "X = np.append(arr = np.ones((50, 1)).astype(int), values = X, axis = 1)\n",
    "X_opt = X[:, [0, 1, 2, 3, 4, 5]]\n",
    "regressor_OLS = sm.OLS(endog = y, exog = X_opt).fit()\n",
    "regressor_OLS.summary()\n",
    "X_opt = X[:, [0, 1, 3, 4, 5]]\n",
    "regressor_OLS = sm.OLS(endog = y, exog = X_opt).fit()\n",
    "regressor_OLS.summary()\n",
    "X_opt = X[:, [0, 3, 4, 5]]\n",
    "regressor_OLS = sm.OLS(endog = y, exog = X_opt).fit()\n",
    "regressor_OLS.summary()\n",
    "X_opt = X[:, [0, 3, 5]]\n",
    "regressor_OLS = sm.OLS(endog = y, exog = X_opt).fit()\n",
    "regressor_OLS.summary()\n",
    "X_opt = X[:, [0, 3]]\n",
    "regressor_OLS = sm.OLS(endog = y, exog = X_opt).fit()\n",
    "regressor_OLS.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Polynomial linear Regressions ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting Linear Regression to the dataset\n",
    "from sklearn.linear_model import LinearRegression\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(X, y)\n",
    "\n",
    "# Fitting Polynomial Regression to the dataset\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "poly_reg = PolynomialFeatures(degree = 4)\n",
    "X_poly = poly_reg.fit_transform(X)\n",
    "poly_reg.fit(X_poly, y)\n",
    "lin_reg_2 = LinearRegression()\n",
    "lin_reg_2.fit(X_poly, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualising the Polynomial Regression results (for higher resolution and smoother curve)\n",
    "X_grid = np.arange(min(X), max(X), 0.1)\n",
    "X_grid = X_grid.reshape((len(X_grid), 1))\n",
    "plt.scatter(X, y, color = 'red')\n",
    "plt.plot(X_grid, lin_reg_2.predict(poly_reg.fit_transform(X_grid)), color = 'blue')\n",
    "plt.title('Truth or Bluff (Polynomial Regression)')\n",
    "plt.xlabel('Position level')\n",
    "plt.ylabel('Salary')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Support Vector Regressions ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a feature Scaler for an SVR\n",
    "\n",
    "# Fitting SVR to the dataset\n",
    "from sklearn.svm import SVR\n",
    "regressor = SVR(kernel = 'rbf')\n",
    "regressor.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Decision Tree Regression ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting Decision Tree Regression to the dataset\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "regressor = DecisionTreeRegressor(random_state = 0)\n",
    "regressor.fit(X, y)\n",
    "\n",
    "# To show the results you need the higher resolution template as it is supposed to act as a staircase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Random Forest Regression ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting Random Forest Regression to the dataset\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "regressor = RandomForestRegressor(n_estimators = 10, random_state = 0)\n",
    "regressor.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Ranking models ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "${R}^{2} = 1 - \\frac{(Sum of residuals vs model)^2}{(Sum against average)^2}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you add a variable in the model, problem is that $R^2$ cannot decrease.\n",
    "\n",
    "Hence comes Adjusted $R^2$ to account for that"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adjusted $R^2 = 1 - (1 - R^2) * \\frac{(n-1)}{(n - p - 1)}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
